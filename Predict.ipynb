{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_clean_2m_line_modified.csv', delimiter=',', nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test_modified.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.drop(['is_booking', 'cnt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_data.pop('id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.pop('hotel_cluster').values.astype('int')\n",
    "train_x = train_data.values\n",
    "test_x = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_five_best(lista=[]):\n",
    "    result=[]\n",
    "    for i in range(0,5):\n",
    "        list_max_value = max(lista)\n",
    "        list_max_index = lista.index(list_max_value)\n",
    "        if(list_max_value>0):\n",
    "            result.append(list_max_index)\n",
    "            del lista[list_max_index]\n",
    "    return str(result).replace(',', '').replace('[','').replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = KNeighborsClassifier()\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 10)\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 50) \n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 100)\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 200)\n",
    "#clf = KNeighborsClassifier(leaf_size = 20, n_neighbors = 200)\n",
    "#clf = KNeighborsClassifier(leaf_size = 10, n_neighbors = 200)\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 10,weights = 'distance')\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 50,weights = 'distance')\n",
    "#clf = KNeighborsClassifier(leaf_size = 100, n_neighbors = 100,weights = 'distance')\n",
    "#clf = KNeighborsClassifier(leaf_size = 20, n_neighbors = 100,weights = 'distance')\n",
    "#clf = KNeighborsClassifier(leaf_size = 10, n_neighbors = 100,weights = 'distance')\n",
    "\n",
    "\n",
    "\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 10, max_features = None, min_samples_leaf = 1, min_samples_split=0.1, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 10, max_features = None, min_samples_leaf = 1, min_samples_split=50, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 32, max_features = None, min_samples_leaf = 1, min_samples_split=50, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 9, max_features = None, min_samples_leaf = 1, min_samples_split=50, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 9, max_features = None, min_samples_leaf = 1, min_samples_split=25, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 10, max_features = None, min_samples_leaf = 1, min_samples_split=50, splitter = 'random')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 9, max_features = None, min_samples_leaf = 0.01, min_samples_split=5, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 9, max_features = None, min_samples_leaf = 0.01, min_samples_split=50, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 32, max_features = None, min_samples_leaf = 1, min_samples_split=25, splitter = 'best')\n",
    "#clf = tree.DecisionTreeClassifier(max_depth = 24, max_features = None, min_samples_leaf = 1, min_samples_split=25, splitter = 'best')\n",
    "\n",
    "\n",
    "\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 9, min_samples_leaf = 1, min_samples_split = 25)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 9, min_samples_leaf = 0.01, min_samples_split = 10)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 22, min_samples_leaf = 0.01, min_samples_split = 0.1)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 23, min_samples_leaf = 1, min_samples_split = 5)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 10, min_samples_leaf = 1, min_samples_split = 10)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 16, min_samples_leaf = 1, min_samples_split = 5)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 10, min_samples_leaf = 1, min_samples_split = 5)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 100, min_samples_leaf = 1, min_samples_split = 5)\n",
    "#clf = tree.ExtraTreeClassifier(max_depth = 9, min_samples_leaf = 1, min_samples_split = 10)\n",
    "\n",
    "\n",
    "#clf = svm.SVC(kernel = 'rbf') \n",
    "#clf = svm.SVC(kernel = 'rbf', gamma = 0.1)\n",
    "#clf = svm.SVC(kernel = 'rbf', gamma = 1)\n",
    "#clf = svm.SVC(kernel = 'rbf', gamma = 10)\n",
    "#clf = svm.SVC(kernel = 'rbf', gamma = 100)\n",
    "#clf = svm.SVC(kernel = 'rbf', gamma = 1000)\n",
    "#clf = svm.SVC(kernel = 'rbf', C = 0.1)\n",
    "#clf = svm.SVC(kernel = 'rbf', C = 1)\n",
    "#clf = svm.SVC(kernel = 'rbf', C = 10)\n",
    "#clf = svm.SVC(kernel = 'rbf', C = 100)\n",
    "#clf = svm.SVC(kernel = 'rbf', C = 1000)\n",
    "\n",
    "\n",
    "\n",
    "#ezeket nem tudtam 100 sorral tesztelni memory error miatt\n",
    "#clf = AdaBoostClassifier()\n",
    "#clf = AdaBoostClassifier(n_estimators = 1)\n",
    "#clf = AdaBoostClassifier(n_estimators = 10)\n",
    "#clf = AdaBoostClassifier(n_estimators = 25)\n",
    "#clf = AdaBoostClassifier(n_estimators = 75)\n",
    "#clf = AdaBoostClassifier(n_estimators = 100)\n",
    "#clf = AdaBoostClassifier(learning_rate = 0.1)\n",
    "#clf = AdaBoostClassifier(learning_rate = 0.5)\n",
    "#clf = AdaBoostClassifier(learning_rate = 1.5)\n",
    "#clf = AdaBoostClassifier(learning_rate = 2.0)\n",
    "#clf = AdaBoostClassifier(learning_rate = 5.0)\n",
    "#clf = AdaBoostClassifier(algorithm = 'SAMME')\n",
    "\n",
    "#clf = MLPClassifier(max_iter = 100)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 1)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 20)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 50)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 100)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 200)memory error\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 500)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 800)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 1000)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 1500)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 2000)\n",
    "#clf = MLPClassifier(max_iter = 100, hidden_layer_sizes = 2500)\n",
    "#clf = MLPClassifier(max_iter = 100, activation = 'identity')\n",
    "#clf = MLPClassifier(max_iter = 100, activation = 'logistic')\n",
    "#clf = MLPClassifier(max_iter = 100, activation = 'tanh')\n",
    "#clf = MLPClassifier(max_iter = 100, solver = 'lbfgs')\n",
    "#clf = MLPClassifier(max_iter = 100, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.0001)\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.0002)\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.0003)\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.0004)\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.001)\n",
    "#clf = MLPClassifier(max_iter = 100, alpha = 0.01)\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate = 'invscaling')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.0015, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.0015, solver = 'adam')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.002, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.002, solver = 'adam')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.0001, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.0001, solver = 'adam')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.003, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.003, solver = 'adam')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.1, solver = 'sgd')\n",
    "#clf = MLPClassifier(max_iter = 100, learning_rate_init = 0.1, solver = 'adam')\n",
    "\n",
    "###\n",
    "#clf = GaussianNB()\n",
    "\n",
    "#clf = RandomForestClassifier(max_depth = 16, max_features = None, min_samples_leaf = 1, min_samples_split = 0.1, n_estimators = 32)\n",
    "#clf = RandomForestClassifier(max_depth = 32, max_features = None, min_samples_leaf = 0.01, min_samples_split = 5, n_estimators = 32)\n",
    "#clf = RandomForestClassifier(max_depth = 10, max_features = None, min_samples_leaf = 1, min_samples_split = 25, n_estimators = 100)\n",
    "clf = RandomForestClassifier(max_depth = 9, max_features = None, min_samples_leaf = 1, min_samples_split = 10, n_estimators = 75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilty Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training start: {}\".format(datetime.datetime.now()))\n",
    "clf.fit(train_x, train_y)\n",
    "print(\"predict start: {}\".format(datetime.datetime.now()))\n",
    "test_y = clf.predict_proba(test_x)\n",
    "print(\"predict end: {}\".format(datetime.datetime.now()))\n",
    "\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = 'id,hotel_cluster\\n'\n",
    "for index, row in test_data.iterrows():\n",
    "    content += str(index) + ',' + get_five_best(list(test_y[index])) + '\\n'\n",
    "file_name = 'result_' + strftime(\"%d%b%Y%H%M%S\", gmtime()) + '.txt'\n",
    "f = open(file_name, 'w')\n",
    "f.write(content)\n",
    "content\n",
    "f.close()\n",
    "print(\"write end: {}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
